{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "minKsat_position.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "EiS5T4ad9gjP",
        "V8i1gZqdj3CJ",
        "_eD_CcYfqR5j",
        "5eDIS7xokQjk",
        "u7mv8sax4tMp",
        "UoHNUINiktFY",
        "QmSuKUDPDbUd"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcJ8O-MPn_31"
      },
      "source": [
        "# Position of the minimum value of Ksat\n",
        "\n",
        "According to the Soil Survey Manual contained in the USDA Handbook the hydrological soil group is increased by one class if the minimum value of Ksat occurs between 0.5 and 1 m. \n",
        "The following code estimate Ksat in three different terrain layers. The value of Ksat is evaluated in two ways: using the method of Rawls and Brakensiek, 1983 and using Rosetta-3a. The first method takes a few minutes to perform the calculations. on the other hand Rosetta require a considerably longer computational time (<10 times). The used methods and code are well described in the file Ksat_Brakeinsiel_Rosetta.ipynb\n",
        "\n",
        "To use the code section for the calculation from Ksat with the Rosetta program, it is necessary to first run the code section using Rawls and Brakensiek, 1983 for the same layer. \n",
        "\n",
        "The layers' inputs used are taken from [soilgrids](https://www.isric.org/explore/soilgrids).\n",
        "\n",
        "The programme output is a required input for the code hydrologic_group.ipynb.\n",
        "\n",
        "**input required:** Ksat.xslx this file contain the graph to obtain the Ksat group using  the Rawls and Brakensiek 1983 method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiS5T4ad9gjP"
      },
      "source": [
        "# 0-60 cm Ksat group estimation (Rawls and Brakensiek, 1983)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yur0JoMO0YBc"
      },
      "source": [
        "pip install owslib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0pnQ69h0bHM"
      },
      "source": [
        "pip install rasterio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck8CIVvqSZiM"
      },
      "source": [
        "# area selection (coords box) it must be provided the bottom lef corner coordinates followed by the top right corner cordinates\n",
        "bbox = (540000, 5400000, 1100000, 5740000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZtUXxI5--GB"
      },
      "source": [
        "# importing the WCS data loading function istalled in the previous section of the code.\n",
        "from owslib.wcs import WebCoverageService\n",
        "# importing the WCS data loading function istalled in the previous section of the code.\n",
        "clay_wcs = WebCoverageService('http://maps.isric.org/mapserv?map=/map/clay.map', version='1.0.0', timeout=120)\n",
        "# load the clay content maps providing the server the map name, the reference system (only few RS are work properly), the pre-defined area object, the resolution and the data format.\n",
        "response = clay_wcs.getCoverage(\n",
        "    identifier='clay_0-5cm_mean', \n",
        "    crs='urn:ogc:def:crs:EPSG::54012',\n",
        "    bbox=bbox, \n",
        "    resx=250, resy=250, \n",
        "    format='GEOTIFF_INT16')\n",
        "# save the loaded file\n",
        "with open('.northIT_clay_0-5_mean.tif', 'wb') as file:\n",
        "    file.write(response.read())\n",
        "# import the saved file as a raster\n",
        "clay0_5 = rasterio.open(\".northIT_clay_0-5_mean.tif\", driver=\"GTiff\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1zg_uAx_Pbv"
      },
      "source": [
        "# load the plot function od rasterio\n",
        "from rasterio import plot as rplt\n",
        "%matplotlib inline\n",
        "# plot the georeferenced data\n",
        "rplt.show(clay0_5, title='north IT % clay 0-5 cm', cmap='pink')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNko4NkBGXMa"
      },
      "source": [
        "# load the clay content maps providing the server the map name, the reference system (only few RS are work properly), the pre-defined area object, the resolution and the data format.\n",
        "response = clay_wcs.getCoverage(\n",
        "    identifier='clay_5-15cm_mean', \n",
        "    crs='urn:ogc:def:crs:EPSG::54012',\n",
        "    bbox=bbox, \n",
        "    resx=250, resy=250, \n",
        "    format='GEOTIFF_INT16')\n",
        "# save the loaded file\n",
        "with open('.northIT_clay_5-15_mean.tif', 'wb') as file:\n",
        "    file.write(response.read())\n",
        "# open the saved file as a raster\n",
        "clay5_15 = rasterio.open(\".northIT_clay_5-15_mean.tif\", driver=\"GTiff\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcmC17QDHU2i"
      },
      "source": [
        "# plot the georeferenced data\n",
        "rplt.show(clay5_15, title='north IT % clay 5 -15 cm', cmap='pink')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOhXJTeXH3Mc"
      },
      "source": [
        "# load the clay content maps providing the server the map name, the reference system (only few RS are work properly), the pre-defined area object, the resolution and the data format.\n",
        "response = clay_wcs.getCoverage(\n",
        "    identifier='clay_15-30cm_mean', \n",
        "    crs='urn:ogc:def:crs:EPSG::54012',\n",
        "    bbox=bbox, \n",
        "    resx=250, resy=250, \n",
        "    format='GEOTIFF_INT16')\n",
        "# save the loaded file\n",
        "with open('.northIT_clay_15-30_mean.tif', 'wb') as file:\n",
        "    file.write(response.read())\n",
        "# import the saved file as a raster\n",
        "clay15_30 = rasterio.open(\".northIT_clay_15-30_mean.tif\", driver=\"GTiff\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3RIx-geICpJ"
      },
      "source": [
        "# plot the georeferenced data\n",
        "rplt.show(clay15_30, title='north IT % clay 15-30 cm', cmap='pink')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yO8aNVTIIXg2"
      },
      "source": [
        "# load the clay content maps providing the server the map name, the reference system (only few RS are work properly), the pre-defined area object, the resolution and the data format.\n",
        "response = clay_wcs.getCoverage(\n",
        "    identifier='clay_30-60cm_mean', \n",
        "    crs='urn:ogc:def:crs:EPSG::54012',\n",
        "    bbox=bbox, \n",
        "    resx=250, resy=250, \n",
        "    format='GEOTIFF_INT16')\n",
        "# save the loaded file\n",
        "with open('.northIT_clay_30-60_mean.tif', 'wb') as file:\n",
        "    file.write(response.read())\n",
        "# import the saved file as a raster\n",
        "clay30_60 = rasterio.open(\".northIT_clay_30-60_mean.tif\", driver=\"GTiff\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkFPW7ygIoLa"
      },
      "source": [
        "# plot the georeferenced data\n",
        "rplt.show(clay30_60, title='north IT % clay 30-60 cm', cmap='pink')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wImecX-bIy16"
      },
      "source": [
        "clay0_60 = clay0_5.read(1)*(5/60) + clay5_15.read(1)*(10/60) + clay15_30.read(1)*(15/60) + clay30_60.read(1)*(30/60)\n",
        "clay060 = clay0_5.meta\n",
        "clay060.update(\n",
        "    dtype=rasterio.float32,\n",
        "    count = 1)\n",
        "\n",
        "# Create the file\n",
        "with rasterio.open('northIT_clay_0-60_mean.tif', 'w', **clay060) as dst:\n",
        "        dst.write_band(1, clay0_60.astype(rasterio.float32))\n",
        "#open the saved file\n",
        "clay060 = rasterio.open(\"northIT_clay_0-60_mean.tif\", driver=\"GTiff\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BingUqDcMCAl"
      },
      "source": [
        "# plot the georeferenced data\n",
        "rplt.show(clay0_60, title='north IT % clay 0-60 cm', cmap='pink')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8g8W99z_RiW"
      },
      "source": [
        "# importing the WCS data loading function istalled in the previous section of the code.\n",
        "sand_wcs = WebCoverageService('http://maps.isric.org/mapserv?map=/map/sand.map', version='1.0.0')\n",
        "# load the sand content maps providing the server the map name, the reference system (only few RS are work properly), the pre-defined area object, the resolution and the data format.\n",
        "response = sand_wcs.getCoverage(\n",
        "    identifier='sand_0-5cm_mean', \n",
        "    crs='urn:ogc:def:crs:EPSG::54012',\n",
        "    bbox=bbox, \n",
        "    resx=250, resy=250, \n",
        "    format='GEOTIFF_INT16')\n",
        "# save the loaded file\n",
        "with open('.northIT_sand_0-5_mean.tif', 'wb') as file:\n",
        "    file.write(response.read())\n",
        "# import the saved file as a raster\n",
        "sand0_5 = rasterio.open(\".northIT_sand_0-5_mean.tif\", driver=\"GTiff\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjRXJVHPTUiL"
      },
      "source": [
        "# plot the georeferenced data\n",
        "rplt.show(sand0_5, title='north IT % sand 0-5 cm', cmap='pink')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WnLKpZZO_Z7"
      },
      "source": [
        "# load the sand content maps providing the server the map name, the reference system (only few RS are work properly), the pre-defined area object, the resolution and the data format.\n",
        "response = sand_wcs.getCoverage(\n",
        "    identifier='sand_5-15cm_mean', \n",
        "    crs='urn:ogc:def:crs:EPSG::54012',\n",
        "    bbox=bbox, \n",
        "    resx=250, resy=250, \n",
        "    format='GEOTIFF_INT16')\n",
        "# save the loaded file\n",
        "with open('.northIT_sand_5-15_mean.tif', 'wb') as file:\n",
        "    file.write(response.read())\n",
        "# import the saved file as a raster\n",
        "sand5_15 = rasterio.open(\".northIT_sand_5-15_mean.tif\", driver=\"GTiff\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1D_eRDcPSHb"
      },
      "source": [
        "# plot the georeferenced data\n",
        "rplt.show(sand5_15, title='north IT % sand 5-15 cm', cmap='pink')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZV7c5RLPXcY"
      },
      "source": [
        "# load the sand content maps providing the server the map name, the reference system (only few RS are work properly), the pre-defined area object, the resolution and the data format.\n",
        "response = sand_wcs.getCoverage(\n",
        "    identifier='sand_15-30cm_mean', \n",
        "    crs='urn:ogc:def:crs:EPSG::54012',\n",
        "    bbox=bbox, \n",
        "    resx=250, resy=250, \n",
        "    format='GEOTIFF_INT16')\n",
        "# save the loaded file\n",
        "with open('.northIT_sand_15-30_mean.tif', 'wb') as file:\n",
        "    file.write(response.read())\n",
        "# import the saved file as a raster\n",
        "sand15_30 = rasterio.open(\".northIT_sand_15-30_mean.tif\", driver=\"GTiff\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLdCV5RIQyON"
      },
      "source": [
        "# plot the georeferenced data\n",
        "rplt.show(sand15_30, title='north IT % sand 15-30 cm', cmap='pink')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14MhL0qzQ-77"
      },
      "source": [
        "# load the sand content maps providing the server the map name, the reference system (only few RS are work properly), the pre-defined area object, the resolution and the data format.\n",
        "response = sand_wcs.getCoverage(\n",
        "    identifier='sand_30-60cm_mean', \n",
        "    crs='urn:ogc:def:crs:EPSG::54012',\n",
        "    bbox=bbox, \n",
        "    resx=250, resy=250, \n",
        "    format='GEOTIFF_INT16')\n",
        "# save the loaded file\n",
        "with open('.northIT_sand_30-60_mean.tif', 'wb') as file:\n",
        "    file.write(response.read())\n",
        "# import the saved file as a raster\n",
        "sand30_60 = rasterio.open(\".northIT_sand_30-60_mean.tif\", driver=\"GTiff\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cTfRh8rROYS"
      },
      "source": [
        "# plot the georeferenced data\n",
        "rplt.show(sand30_60, title='north IT % sand 30-60 cm', cmap='pink')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEsZalOOR5R0"
      },
      "source": [
        "sand0_60 = sand0_5.read(1)*(5/60) + sand5_15.read(1)*(10/60) + sand15_30.read(1)*(15/60) + sand30_60.read(1)*(30/60)\n",
        "sand060 = sand0_5.meta\n",
        "sand060.update(\n",
        "    dtype=rasterio.float32,\n",
        "    count = 1)\n",
        "\n",
        "# Create the file\n",
        "with rasterio.open('northIT_sand_0-60_mean.tif', 'w', **sand060) as dst:\n",
        "        dst.write_band(1, sand0_60.astype(rasterio.float32))\n",
        "#open the saved file\n",
        "sand060 = rasterio.open(\"northIT_sand_0-60_mean.tif\", driver=\"GTiff\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBAwKc1cSfGu"
      },
      "source": [
        "# plot the georeferenced data\n",
        "rplt.show(sand0_60, title='north IT % sand 0-60 cm', cmap='pink')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlPLNwySU2NO"
      },
      "source": [
        "# importing the WCS data loading function istalled in the previous section of the code.\n",
        "bdod_wcs = WebCoverageService('http://maps.isric.org/mapserv?map=/map/bdod.map', version='1.0.0')\n",
        "# load the bulck density maps providing the server the map name, the reference system (only few RS are work properly), the pre-defined area object, the resolution and the data format.\n",
        "response = bdod_wcs.getCoverage(\n",
        "    identifier='bdod_0-5cm_mean', \n",
        "    crs='urn:ogc:def:crs:EPSG::54012',\n",
        "    bbox=bbox, \n",
        "    resx=250, resy=250, \n",
        "    format='GEOTIFF_INT16')\n",
        "# save the loaded file\n",
        "with open('.northIT_bdod_0-5_mean.tif', 'wb') as file:\n",
        "    file.write(response.read())\n",
        "# import the saved file as a raster\n",
        "bdod0_5 = rasterio.open(\".northIT_bdod_0-5_mean.tif\", driver=\"GTiff\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPXuTWCoUyd0"
      },
      "source": [
        "# plot the georeferenced data\n",
        "rplt.show(bdod0_5, title='north IT bulk density 0-5 cm', cmap='pink')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A75gMYs1T6iK"
      },
      "source": [
        "# load the bulk density maps providing the server the map name, the reference system (only few RS are work properly), the pre-defined area object, the resolution and the data format.\n",
        "response = bdod_wcs.getCoverage(\n",
        "    identifier='bdod_5-15cm_mean', \n",
        "    crs='urn:ogc:def:crs:EPSG::54012',\n",
        "    bbox=bbox, \n",
        "    resx=250, resy=250, \n",
        "    format='GEOTIFF_INT16')\n",
        "# save the loaded file\n",
        "with open('.northIT_bdod_5-15_mean.tif', 'wb') as file:\n",
        "    file.write(response.read())\n",
        "# import the saved file as a raster\n",
        "\n",
        "bdod5_15 = rasterio.open(\".northIT_bdod_5-15_mean.tif\", driver=\"GTiff\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDfi-AZmUoTR"
      },
      "source": [
        "# plot the georeferenced data\n",
        "rplt.show(bdod5_15, title='north IT bulk density 5-15 cm', cmap='pink')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKw-etMuUwRj"
      },
      "source": [
        "# load the bulk density maps providing the server the map name, the reference system (only few RS are work properly), the pre-defined area object, the resolution and the data format.\n",
        "response = bdod_wcs.getCoverage(\n",
        "    identifier='bdod_15-30cm_mean', \n",
        "    crs='urn:ogc:def:crs:EPSG::54012',\n",
        "    bbox=bbox, \n",
        "    resx=250, resy=250, \n",
        "    format='GEOTIFF_INT16')\n",
        "# save the loaded file\n",
        "with open('.northIT_bdod_15-30_mean.tif', 'wb') as file:\n",
        "    file.write(response.read())\n",
        "# import the saved file as a raster\n",
        "bdod15_30 = rasterio.open(\".northIT_bdod_15-30_mean.tif\", driver=\"GTiff\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqvYfoQYU_sJ"
      },
      "source": [
        "# plot the georeferenced data\n",
        "rplt.show(bdod15_30, title='north IT bulk density 15-30 cm', cmap='pink')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqLv_G-VVG1i"
      },
      "source": [
        "# load the bulk density maps providing the server the map name, the reference system (only few RS are work properly), the pre-defined area object, the resolution and the data format.\n",
        "response = bdod_wcs.getCoverage(\n",
        "    identifier='bdod_30-60cm_mean', \n",
        "    crs='urn:ogc:def:crs:EPSG::54012',\n",
        "    bbox=bbox, \n",
        "    resx=250, resy=250, \n",
        "    format='GEOTIFF_INT16')\n",
        "# save the loaded file\n",
        "with open('.northIT_bdod_30-60_mean.tif', 'wb') as file:\n",
        "    file.write(response.read())\n",
        "# import the saved file as a raster\n",
        "bdod30_60 = rasterio.open(\".northIT_bdod_30-60_mean.tif\", driver=\"GTiff\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do6-vh8WVN4G"
      },
      "source": [
        "# plot the georeferenced data\n",
        "rplt.show(bdod30_60, title='north IT bulk density 30-60 cm', cmap='pink')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m39sP5fSVXyV"
      },
      "source": [
        "bdod0_60 = bdod0_5.read(1)*(5/60) + bdod5_15.read(1)*(10/60) + bdod15_30.read(1)*(15/60) + bdod30_60.read(1)*(30/60)\n",
        "bdod060 = bdod0_5.meta\n",
        "bdod060.update(\n",
        "    dtype=rasterio.float32,\n",
        "    count = 1)\n",
        "\n",
        "# Create the file\n",
        "with rasterio.open('northIT_bdod_0-60_mean.tif', 'w', **bdod060) as dst:\n",
        "        dst.write_band(1, bdod0_60.astype(rasterio.float32))\n",
        "#open the saved file\n",
        "bdod060 = rasterio.open(\"northIT_bdod_0-60_mean.tif\", driver=\"GTiff\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiRMQAPfWHFh"
      },
      "source": [
        "# plot the georeferenced data\n",
        "rplt.show(bdod0_60, title='north IT bulk density 0-60 cm', cmap='pink')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1h4AjWRwIyd"
      },
      "source": [
        "In the next section is also loaded the silt content. It is done to check the data of clay and sand. The sum of the three concentrations must be one. the silt content will be used for the evalutation with Rosetta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lGxBUqLCfW2"
      },
      "source": [
        "silt_wcs = WebCoverageService('http://maps.isric.org/mapserv?map=/map/silt.map', version='1.0.0')\n",
        "response = silt_wcs.getCoverage(\n",
        "    identifier='silt_0-5cm_mean', \n",
        "    crs='urn:ogc:def:crs:EPSG::54012',\n",
        "    bbox=bbox, \n",
        "    resx=250, resy=250, \n",
        "    format='GEOTIFF_INT16')\n",
        "with open('.northIT_silt_0-5_mean.tif', 'wb') as file:\n",
        "    file.write(response.read())\n",
        "silt0_5 = rasterio.open(\".northIT_silt_0-5_mean.tif\", driver=\"GTiff\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmpCBMLJWfqP"
      },
      "source": [
        "response = silt_wcs.getCoverage(\n",
        "    identifier='silt_5-15cm_mean', \n",
        "    crs='urn:ogc:def:crs:EPSG::54012',\n",
        "    bbox=bbox, \n",
        "    resx=250, resy=250, \n",
        "    format='GEOTIFF_INT16')\n",
        "with open('.northIT_silt_5-15_mean.tif', 'wb') as file:\n",
        "    file.write(response.read())\n",
        "silt5_15 = rasterio.open(\".northIT_silt_5-15_mean.tif\", driver=\"GTiff\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toaYOiSEWnul"
      },
      "source": [
        "response = silt_wcs.getCoverage(\n",
        "    identifier='silt_15-30cm_mean', \n",
        "    crs='urn:ogc:def:crs:EPSG::54012',\n",
        "    bbox=bbox, \n",
        "    resx=250, resy=250, \n",
        "    format='GEOTIFF_INT16')\n",
        "with open('.northIT_silt_15-30_mean.tif', 'wb') as file:\n",
        "    file.write(response.read())\n",
        "silt15_30 = rasterio.open(\".northIT_silt_15-30_mean.tif\", driver=\"GTiff\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0WPfyN2Wuhr"
      },
      "source": [
        "response = silt_wcs.getCoverage(\n",
        "    identifier='silt_30-60cm_mean', \n",
        "    crs='urn:ogc:def:crs:EPSG::54012',\n",
        "    bbox=bbox, \n",
        "    resx=250, resy=250, \n",
        "    format='GEOTIFF_INT16')\n",
        "with open('.northIT_silt_30-60_mean.tif', 'wb') as file:\n",
        "    file.write(response.read())\n",
        "silt30_60 = rasterio.open(\".northIT_silt_30-60_mean.tif\", driver=\"GTiff\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jx8vb5RfW2v0"
      },
      "source": [
        "silt0_60 = silt0_5.read(1)*(5/60) + silt5_15.read(1)*(10/60) + silt15_30.read(1)*(15/60) + silt30_60.read(1)*(30/60)\n",
        "silt060 = silt0_5.meta\n",
        "silt060.update(\n",
        "    dtype=rasterio.float32,\n",
        "    count = 1)\n",
        "\n",
        "# Create the file\n",
        "with rasterio.open('northIT_silt_0-60_mean.tif', 'w', **silt060) as dst:\n",
        "        dst.write_band(1, silt0_60.astype(rasterio.float32))\n",
        "#open the saved file\n",
        "silt060 = rasterio.open(\"northIT_silt_0-60_mean.tif\", driver=\"GTiff\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvU_R6g0XbjO"
      },
      "source": [
        "# plot the georeferenced data\n",
        "rplt.show(silt0_60, title='north IT silt density 0-60 cm', cmap='pink')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0BZ57vKcEXI"
      },
      "source": [
        "#import mat plot lib in order to plot the color bar\n",
        "import matplotlib.pyplot as plt\n",
        "#sum Clay Sand and Silt content (in g/kg) and divide it by 1000 to obtain a fraction\n",
        "verifica = (sand060.read(1)+silt060.read(1)+clay060.read(1))/1000\n",
        "#plot the immage and the color bar.\n",
        "plt.imshow(verifica)\n",
        "plt.colorbar()\n",
        "plt.title('verification graph')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGPZ8ijoAsfY"
      },
      "source": [
        "# import the pandas library for the dataframe managing\n",
        "import pandas as pd\n",
        "# import form the shaply library the fuction point and Polygon to trasform the \n",
        "# input raster gfeoreferenced data into a table point object and to transform \n",
        "# the loaded Table's polygon point in to a Polygon object\n",
        "from shapely.geometry import Point\n",
        "from shapely.geometry.polygon import Polygon\n",
        "\n",
        "#first chek of input data, if the poin are out of the polygon data raise an error\n",
        "if ((sand060.read(1)+silt060.read(1))> 1000).any():\n",
        "    raise Exception ('sand and clay % excede the 100%. check the input data!')\n",
        "\n",
        "# load data from the .xlsx file and transform them in Polygons \n",
        "hbd=pd.read_excel('Ksat.xlsx',sheet_name='high bulk density poli') #high bulk density\n",
        "hbd_1 = pd.DataFrame(hbd, columns= ['poligono 1 x','poligono 1 y'])\n",
        "hbd_1.dropna(subset = [\"poligono 1 x\"], inplace=True)\n",
        "hbd_1p=Polygon(hbd_1.values.tolist())\n",
        "hbd_2 = pd.DataFrame(hbd, columns= ['poligono 2 x','poligono 2 y'])\n",
        "hbd_2.dropna(subset = [\"poligono 2 x\"], inplace=True)\n",
        "hbd_2p=Polygon(hbd_2.values.tolist())\n",
        "hbd_3 = pd.DataFrame(hbd, columns= ['poligono 3 x','poligono 3 y'])\n",
        "hbd_3p=Polygon(hbd_3.values.tolist())\n",
        "hbd_3.dropna(subset = [\"poligono 3 x\"], inplace=True)\n",
        "hbd_4 = pd.DataFrame(hbd, columns= ['poligono 4 x','poligono 4 y'])\n",
        "hbd_4.dropna(subset = [\"poligono 4 x\"], inplace=True)\n",
        "hbd_4p=Polygon(hbd_4.values.tolist())\n",
        "hbd_5 = pd.DataFrame(hbd, columns= ['poligono 5 x','poligono 5 y'])\n",
        "hbd_5.dropna(subset = [\"poligono 5 x\"], inplace=True)\n",
        "hbd_5p=Polygon(hbd_5.values.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IR9hpiS2Asfa"
      },
      "source": [
        "mbd=pd.read_excel('Ksat.xlsx',sheet_name='med bulk density poli') #med bulk density\n",
        "mbd_1 = pd.DataFrame(mbd, columns= ['poligono 1 x','poligono 1 y'])\n",
        "mbd_1.dropna(subset = [\"poligono 1 x\"], inplace=True)\n",
        "mbd_1p=Polygon(mbd_1.values.tolist())\n",
        "mbd_2 = pd.DataFrame(mbd, columns= ['poligono 2 x','poligono 2 y'])\n",
        "mbd_2.dropna(subset = [\"poligono 2 x\"], inplace=True)\n",
        "mbd_2p=Polygon(mbd_2.values.tolist())\n",
        "mbd_3 = pd.DataFrame(mbd, columns= ['poligono 3 x','poligono 3 y'])\n",
        "mbd_3p=Polygon(mbd_3.values.tolist())\n",
        "mbd_3.dropna(subset = [\"poligono 3 x\"], inplace=True)\n",
        "mbd_4 = pd.DataFrame(mbd, columns= ['poligono 4 x','poligono 4 y'])\n",
        "mbd_4.dropna(subset = [\"poligono 4 x\"], inplace=True)\n",
        "mbd_4p=Polygon(mbd_4.values.tolist())\n",
        "mbd_5 = pd.DataFrame(mbd, columns= ['poligono 5 x','poligono 5 y'])\n",
        "mbd_5.dropna(subset = [\"poligono 5 x\"], inplace=True)\n",
        "mbd_5p=Polygon(mbd_5.values.tolist())\n",
        "mbd_6 = pd.DataFrame(mbd, columns= ['poligono 6 x','poligono 6 y'])\n",
        "mbd_6.dropna(subset = [\"poligono 6 x\"], inplace=True)\n",
        "mbd_6p=Polygon(mbd_6.values.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpMbD8YYAsfb"
      },
      "source": [
        "lbd=pd.read_excel('Ksat.xlsx',sheet_name='low bulk density poli') #led bulk density\n",
        "lbd_1 = pd.DataFrame(lbd, columns= ['poligono 1 x','poligono 1 y'])\n",
        "lbd_1.dropna(subset = [\"poligono 1 x\"], inplace=True)\n",
        "lbd_1p=Polygon(lbd_1.values.tolist())\n",
        "lbd_2 = pd.DataFrame(lbd, columns= ['poligono 2 x','poligono 2 y'])\n",
        "lbd_2.dropna(subset = [\"poligono 2 x\"], inplace=True)\n",
        "lbd_2p=Polygon(lbd_2.values.tolist())\n",
        "lbd_3 = pd.DataFrame(lbd, columns= ['poligono 3 x','poligono 3 y'])\n",
        "lbd_3p=Polygon(lbd_3.values.tolist())\n",
        "lbd_3.dropna(subset = [\"poligono 3 x\"], inplace=True)\n",
        "lbd_4 = pd.DataFrame(lbd, columns= ['poligono 4 x','poligono 4 y'])\n",
        "lbd_4.dropna(subset = [\"poligono 4 x\"], inplace=True)\n",
        "lbd_4p=Polygon(lbd_4.values.tolist())\n",
        "lbd_5 = pd.DataFrame(lbd, columns= ['poligono 5 x','poligono 5 y'])\n",
        "lbd_5.dropna(subset = [\"poligono 5 x\"], inplace=True)\n",
        "lbd_5p=Polygon(lbd_5.values.tolist())\n",
        "lbd_6 = pd.DataFrame(lbd, columns= ['poligono 6 x','poligono 6 y'])\n",
        "lbd_6.dropna(subset = [\"poligono 6 x\"], inplace=True)\n",
        "lbd_6p=Polygon(lbd_6.values.tolist())\n",
        "lbd_7 = pd.DataFrame(lbd, columns= ['poligono 7 x','poligono 7 y'])\n",
        "lbd_7.dropna(subset = [\"poligono 7 x\"], inplace=True)\n",
        "lbd_7p=Polygon(lbd_7.values.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqO9B672AyN7"
      },
      "source": [
        "#transform the input data ind datagrame and det them in the tables unit of measure\n",
        "x = sand060.read(1)/1000\n",
        "y = clay060.read(1)/1000\n",
        "z = bdod060.read(1)/100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-aNFgSmhf8p"
      },
      "source": [
        "# import numpy because it will be needed in the definde fucntion\n",
        "import numpy as np\n",
        "# define a function for the bulk density class selection\n",
        "def bd_group_selector(x,y,z,lbd_6p,lbd_5p,lbd_4p,lbd_3p,lbd_2p,lbd_1p,lbd_7p,mbd_6p,mbd_5p,mbd_4p,mbd_3p,mbd_2p,mbd_1p,hbd_5p,hbd_4p,hbd_3p,hbd_2p,hbd_1p):\n",
        "  bd_group = np.zeros(np.shape(x))\n",
        "  for i in range(np.shape(x)[0]):\n",
        "    for j in range(np.shape(x)[1]):\n",
        "     point = Point(x[i,j],y[i,j])\n",
        "     if x[i,j] == 0 and y[i,j] == 0: #mare o  no data\n",
        "       bd_group[i,j] = -1\n",
        "     elif lbd_7p.contains(point) and z[i,j]<1.19:\n",
        "       bd_group[i,j] = 1\n",
        "     elif lbd_6p.contains(point) and z[i,j]<0.93:\n",
        "       bd_group[i,j] = 1\n",
        "     elif lbd_5p.contains(point) and z[i,j]<1.32:\n",
        "       bd_group[i,j] = 1\n",
        "     elif lbd_4p.contains(point) and z[i,j]<1.06:\n",
        "       bd_group[i,j] = 1\n",
        "     elif lbd_3p.contains(point) and z[i,j]<1.32:\n",
        "       bd_group[i,j] = 1\n",
        "     elif lbd_2p.contains(point) and z[i,j]<1.06:\n",
        "       bd_group[i,j] = 1\n",
        "     elif lbd_1p.contains(point) and z[i,j]<0.93:  \n",
        "       bd_group[i,j] = 1 \n",
        "     elif hbd_5p.contains(point) and 1.72<z[i,j]:\n",
        "       bd_group[i,j] = 3      \n",
        "     elif hbd_4p.contains(point) and 1.19<z[i,j]:\n",
        "       bd_group[i,j] = 3 \n",
        "     elif hbd_3p.contains(point) and 1.46<z[i,j]:\n",
        "       bd_group[i,j] = 3 \n",
        "     elif hbd_2p.contains(point) and 1.59<z[i,j]:\n",
        "       bd_group[i,j] = 3 \n",
        "     elif hbd_1p.contains(point) and 1.32<z[i,j]:\n",
        "       bd_group[i,j] = 3\n",
        "     elif mbd_6p.contains(point) and 1.59<=z[i,j]<=1.72:\n",
        "       bd_group[i,j] = 2\n",
        "     elif mbd_5p.contains(point) and 1.48<=z[i,j]<=1.72:\n",
        "       bd_group[i,j] = 2\n",
        "     elif mbd_4p.contains(point) and 0.93<=z[i,j]<=1.19:\n",
        "       bd_group[i,j] = 2\n",
        "     elif mbd_3p.contains(point) and 1.19<=z[i,j]<=1.46:\n",
        "       bd_group[i,j] = 2\n",
        "     elif mbd_2p.contains(point) and 1.30<=z[i,j]<=1.48:\n",
        "       bd_group[i,j] = 2\n",
        "     else:\n",
        "       bd_group[i,j] = 0\n",
        "  return bd_group\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wY18RAuqAyN-"
      },
      "source": [
        "bd_group = bd_group_selector(x,y,z,lbd_6p,lbd_5p,lbd_4p,lbd_3p,lbd_2p,lbd_1p,lbd_7p,mbd_6p,mbd_5p,mbd_4p,mbd_3p,mbd_2p,mbd_1p,hbd_5p,hbd_4p,hbd_3p,hbd_2p,hbd_1p)\n",
        "\n",
        "plt.imshow(bd_group)\n",
        "plt.colorbar()\n",
        "plt.title('bulck density group')\n",
        "plt.xlabel('Column #')\n",
        "plt.ylabel('Row #')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUSx0wTjBAw7"
      },
      "source": [
        "# Ksat Goup table loading \n",
        "Ksat=pd.read_excel('Ksat.xlsx',sheet_name='GI High bulk') #med bulk density\n",
        "hb_l_ksat= pd.DataFrame(Ksat, columns= ['low x','low y'])\n",
        "hb_l_ksat.dropna(subset = [\"low x\"], inplace=True)\n",
        "hb_l_ksatp=Polygon(hb_l_ksat.values.tolist())\n",
        "hb_ml_ksat = pd.DataFrame(Ksat, columns= ['mod low x','mod low y'])\n",
        "hb_ml_ksat.dropna(subset = [\"mod low x\"], inplace=True)\n",
        "hb_ml_ksatp = Polygon(hb_ml_ksat.values.tolist())\n",
        "hb_mh_ksat = pd.DataFrame(Ksat, columns= ['mod high x','mod high y'])\n",
        "hb_mh_ksat.dropna(subset = ['mod high x'], inplace=True)\n",
        "hb_mh_ksatp=Polygon(hb_mh_ksat.values.tolist())\n",
        "\n",
        "Ksat=pd.read_excel('Ksat.xlsx',sheet_name='GI Med bulk') #med bulk density\n",
        "mb_l_ksat= pd.DataFrame(Ksat, columns= ['low x','low y'])\n",
        "mb_l_ksat.dropna(subset = [\"low x\"], inplace=True)\n",
        "mb_l_ksatp=Polygon(mb_l_ksat.values.tolist())\n",
        "mb_ml_ksat = pd.DataFrame(Ksat, columns= ['mod low x','mod low y'])\n",
        "mb_ml_ksat.dropna(subset = [\"mod low x\"], inplace=True)\n",
        "mb_ml_ksatp = Polygon(mb_ml_ksat.values.tolist())\n",
        "mb_mh_ksat = pd.DataFrame(Ksat, columns= ['mod high x','mod high y'])\n",
        "mb_mh_ksat.dropna(subset = ['mod high x'], inplace=True)\n",
        "mb_mh_ksatp=Polygon(mb_mh_ksat.values.tolist())\n",
        "mb_h_ksat = pd.DataFrame(Ksat, columns= ['high x','high y'])\n",
        "mb_h_ksat.dropna(subset = ['high x'], inplace=True)\n",
        "mb_h_ksatp=Polygon(mb_h_ksat.values.tolist())\n",
        "\n",
        "\n",
        "Ksat=pd.read_excel('Ksat.xlsx',sheet_name='GI Low bulk') #med bulk density\n",
        "lb_ml_ksat = pd.DataFrame(Ksat, columns= ['mod low x','mod low y'])\n",
        "lb_ml_ksat.dropna(subset = [\"mod low x\"], inplace=True)\n",
        "lb_ml_ksatp = Polygon(lb_ml_ksat.values.tolist())\n",
        "lb_mh_ksat = pd.DataFrame(Ksat, columns= ['mod high x','mod high y'])\n",
        "lb_mh_ksat.dropna(subset = ['mod high x'], inplace=True)\n",
        "lb_mh_ksatp=Polygon(lb_mh_ksat.values.tolist())\n",
        "lb_h_ksat = pd.DataFrame(Ksat, columns= ['high x','high y'])\n",
        "lb_h_ksat.dropna(subset = ['high x'], inplace=True)\n",
        "lb_h_ksatp=Polygon(lb_h_ksat.values.tolist())\n",
        "\n",
        "\n",
        "#Ksat Group assignement\n",
        "\n",
        "GKsat = np.zeros(np.shape(x))\n",
        "GKsatm = (1)\n",
        "for i in range(np.shape(x)[0]):\n",
        "    for j in range(np.shape(x)[1]):\n",
        "        point = Point(x[i,j],y[i,j])\n",
        "        if bd_group[i,j] == -1: #mare lago o no data\n",
        "            GKsat[i,j] = -1\n",
        "        elif bd_group [i,j] == 1:\n",
        "            if lb_ml_ksatp.contains(point):\n",
        "                GKsat[i,j] = 2\n",
        "            elif lb_mh_ksatp.contains(point):\n",
        "                GKsat[i,j] = 3\n",
        "            elif lb_h_ksatp.contains(point):\n",
        "                GKsat[i,j] = 4\n",
        "        elif bd_group [i,j] == 2:\n",
        "            if mb_l_ksatp.contains(point):\n",
        "                GKsat[i,j] = 1\n",
        "            elif mb_ml_ksatp.contains(point):\n",
        "                GKsat[i,j] = 2\n",
        "            elif mb_mh_ksatp.contains(point):\n",
        "                GKsat[i,j] = 3\n",
        "            elif mb_h_ksatp.contains(point):\n",
        "                GKsat[i,j] = 4\n",
        "        elif bd_group [i,j] == 3:\n",
        "            if hb_l_ksatp.contains(point):\n",
        "                GKsat[i,j] = 1\n",
        "            elif hb_ml_ksatp.contains(point):\n",
        "                GKsat[i,j] = 2\n",
        "            elif hb_mh_ksatp.contains(point):\n",
        "                GKsat[i,j] = 3\n",
        "        elif bd_group [i,j] == 0:\n",
        "            GKsat[i,j] = GKsatm\n",
        "        Gksatm = GKsat[i,j] # dato precedente: se il dato non Ã¨ presente viene assegnato il gruppo della cella accanto\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olqzBcmwBAw-"
      },
      "source": [
        "# numer of cells with not enough data\n",
        "print(sum(sum(bd_group==0))/(np.shape(bd_group)[0]*np.shape(bd_group)[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itZBfbwGBAxA"
      },
      "source": [
        "# result plotting \n",
        "plt.imshow(GKsat, cmap='Set1',)\n",
        "plt.colorbar()\n",
        "plt.title('Ksat group')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8JmRE6FBAxB"
      },
      "source": [
        "# save Ksat group\n",
        "Group_ksat = silt060.meta\n",
        "Group_ksat.update(\n",
        "    dtype=rasterio.float32,\n",
        "    count = 1)\n",
        "\n",
        "# Create the file\n",
        "with rasterio.open('Group_ksat0-60.tif', 'w', **Group_ksat) as dst:\n",
        "        dst.write_band(1, GKsat.astype(rasterio.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8i1gZqdj3CJ"
      },
      "source": [
        "#0-60 cm Ksat group estimation (Rosetta)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UITcq6qKhj2o"
      },
      "source": [
        "#split the input in 100 pieces to reduce the RAM required\n",
        "sand_c060 = sand060.read(1).flatten()/1000\n",
        "silt_c060 = silt060.read(1).flatten()/1000\n",
        "clay_c060 = clay060.read(1).flatten()/1000\n",
        "bd_c060 = bdod060.read(1).flatten()/100\n",
        "split_sand_c060 = np.split(sand_c060,100)\n",
        "split_silt_c060 = np.split(silt_c060,100)\n",
        "split_clay_c060 = np.split(clay_c060,100)\n",
        "split_bd_c060 = np.split(bd_c060,100)\n",
        "\n",
        "dim=(np.shape(sand_c060)[0])\n",
        "Ksat = np.zeros(dim)\n",
        "start = 0\n",
        "for i in range(100):\n",
        "  input_data = np.column_stack((split_sand_c060[i],split_silt_c060[i],split_clay_c060[i],split_bd_c060[i]))\n",
        "  np.savetxt('input_data.txt', input_data)\n",
        "  #create an empity output file\n",
        "  output_data  = np.array([0,0])\n",
        "  np.savetxt('output_data.txt', output_data)\n",
        "  %run /content/drive/MyDrive/Rosetta_3/Rpredict.py   -i   input_data.txt  -o  output_data.txt --predict  --sqlite=/content/drive/MyDrive/Rosetta_3/sqlite/Rosetta.sqlite\n",
        "  output = np.loadtxt('output_data.txt', delimiter=',')\n",
        "  finish = start+int(dim/100) \n",
        "  Ksat [start:finish] = output[:,4]\n",
        "  start = finish\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlhbOrI7hmDS"
      },
      "source": [
        "#save the results\n",
        "np.savetxt('Ksat.txt', Ksat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s5D_CAYhm58"
      },
      "source": [
        "#rechape the results to image dimension\n",
        "Ksat_Rosetta = np.loadtxt('Ksat.txt', dtype= float)\n",
        "Ksat_R_img = np.reshape(Ksat_Rosetta,[1360,2240])\n",
        "Ksat_R_img = Ksat_R_img*(GKsat>0)+(GKsat<=0)*-75"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erfi9vfehqo1"
      },
      "source": [
        "#plot the results\n",
        "plt.imshow(Ksat_R_img, cmap='Set1',)\n",
        "plt.colorbar()\n",
        "plt.title('Ksat')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGMDVvr4hr7x"
      },
      "source": [
        "# save Ksat group\n",
        "ksat_Rosetta = silt060.meta\n",
        "ksat_Rosetta.update(\n",
        "    dtype=rasterio.float32,\n",
        "    count = 1)\n",
        "\n",
        "# Create the file\n",
        "with rasterio.open('ksat_Rosetta_0_60.tif', 'w', **ksat_Rosetta) as dst:\n",
        "        dst.write_band(1, Ksat_R_img.astype(rasterio.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eD_CcYfqR5j"
      },
      "source": [
        "# 60-100 cm Ksat group estimation  (Rawls and Brakensiek, 1983)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKAI-7_ak6QM"
      },
      "source": [
        "# load the clay content maps providing the server the map name, the reference system (only few RS are work properly), the pre-defined area object, the resolution and the data format.\n",
        "response = clay_wcs.getCoverage(\n",
        "    identifier='clay_60-100cm_mean', \n",
        "    crs='urn:ogc:def:crs:EPSG::54012',\n",
        "    bbox=bbox, \n",
        "    resx=250, resy=250, \n",
        "    format='GEOTIFF_INT16')\n",
        "# save the loaded file\n",
        "with open('.northIT_clay_60-100_mean.tif', 'wb') as file:\n",
        "    file.write(response.read())\n",
        "# import the saved file as a raster\n",
        "import rasterio\n",
        "clay60100 = rasterio.open(\".northIT_clay_60-100_mean.tif\", driver=\"GTiff\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69GoNbkUpL0v"
      },
      "source": [
        "# load the sand content maps providing the server the map name, the reference system (only few RS are work properly), the pre-defined area object, the resolution and the data format.\n",
        "response = sand_wcs.getCoverage(\n",
        "    identifier='sand_60-100cm_mean', \n",
        "    crs='urn:ogc:def:crs:EPSG::54012',\n",
        "    bbox=bbox, \n",
        "    resx=250, resy=250, \n",
        "    format='GEOTIFF_INT16')\n",
        "# save the loaded file\n",
        "with open('.northIT_sand_60-100_mean.tif', 'wb') as file:\n",
        "    file.write(response.read())\n",
        "# import the saved file as a raster\n",
        "sand60100 = rasterio.open(\".northIT_sand_60-100_mean.tif\", driver=\"GTiff\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usnqx7rdpb9Z"
      },
      "source": [
        "# load the bulck density maps providing the server the map name, the reference system (only few RS are work properly), the pre-defined area object, the resolution and the data format.\n",
        "response = bdod_wcs.getCoverage(\n",
        "    identifier='bdod_60-100cm_mean', \n",
        "    crs='urn:ogc:def:crs:EPSG::54012',\n",
        "    bbox=bbox, \n",
        "    resx=250, resy=250, \n",
        "    format='GEOTIFF_INT16')\n",
        "# save the loaded file\n",
        "with open('.northIT_bdod_60-100_mean.tif', 'wb') as file:\n",
        "    file.write(response.read())\n",
        "# import the saved file as a raster\n",
        "bdod60100 = rasterio.open(\".northIT_bdod_60-100_mean.tif\", driver=\"GTiff\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7ftw3lxpqUo"
      },
      "source": [
        "response = silt_wcs.getCoverage(\n",
        "    identifier='silt_60-100cm_mean', \n",
        "    crs='urn:ogc:def:crs:EPSG::54012',\n",
        "    bbox=bbox, \n",
        "    resx=250, resy=250, \n",
        "    format='GEOTIFF_INT16')\n",
        "with open('.northIT_silt_60-100_mean.tif', 'wb') as file:\n",
        "    file.write(response.read())\n",
        "silt60100 = rasterio.open(\".northIT_silt_60-100_mean.tif\", driver=\"GTiff\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M18_n_drMEY"
      },
      "source": [
        "#transform the input data ind datagrame and det them in the tables unit of measure\n",
        "x = sand60100.read(1)/1000\n",
        "y = clay60100.read(1)/1000\n",
        "z = bdod60100.read(1)/100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5EVsZn2qaS3"
      },
      "source": [
        "# import the pandas library for the dataframe managing\n",
        "import pandas as pd\n",
        "# import form the shaply library the fuction point and Polygon to trasform the \n",
        "# input raster gfeoreferenced data into a table point object and to transform \n",
        "# the loaded Table's polygon point in to a Polygon object\n",
        "from shapely.geometry import Point\n",
        "from shapely.geometry.polygon import Polygon\n",
        "\n",
        "#first chek of input data, if the poin are out of the polygon data raise an error\n",
        "if ((sand60100.read(1)+silt60100.read(1))> 1000).any():\n",
        "    raise Exception ('sand and clay % excede the 100%. check the input data!')\n",
        "\n",
        "# load data from the .xlsx file and transform them in Polygons \n",
        "hbd=pd.read_excel('Ksat.xlsx',sheet_name='high bulk density poli') #high bulk density\n",
        "hbd_1 = pd.DataFrame(hbd, columns= ['poligono 1 x','poligono 1 y'])\n",
        "hbd_1.dropna(subset = [\"poligono 1 x\"], inplace=True)\n",
        "hbd_1p=Polygon(hbd_1.values.tolist())\n",
        "hbd_2 = pd.DataFrame(hbd, columns= ['poligono 2 x','poligono 2 y'])\n",
        "hbd_2.dropna(subset = [\"poligono 2 x\"], inplace=True)\n",
        "hbd_2p=Polygon(hbd_2.values.tolist())\n",
        "hbd_3 = pd.DataFrame(hbd, columns= ['poligono 3 x','poligono 3 y'])\n",
        "hbd_3p=Polygon(hbd_3.values.tolist())\n",
        "hbd_3.dropna(subset = [\"poligono 3 x\"], inplace=True)\n",
        "hbd_4 = pd.DataFrame(hbd, columns= ['poligono 4 x','poligono 4 y'])\n",
        "hbd_4.dropna(subset = [\"poligono 4 x\"], inplace=True)\n",
        "hbd_4p=Polygon(hbd_4.values.tolist())\n",
        "hbd_5 = pd.DataFrame(hbd, columns= ['poligono 5 x','poligono 5 y'])\n",
        "hbd_5.dropna(subset = [\"poligono 5 x\"], inplace=True)\n",
        "hbd_5p=Polygon(hbd_5.values.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqGHsuJHmo8U"
      },
      "source": [
        "mbd=pd.read_excel('Ksat.xlsx',sheet_name='med bulk density poli') #med bulk density\n",
        "mbd_1 = pd.DataFrame(mbd, columns= ['poligono 1 x','poligono 1 y'])\n",
        "mbd_1.dropna(subset = [\"poligono 1 x\"], inplace=True)\n",
        "mbd_1p=Polygon(mbd_1.values.tolist())\n",
        "mbd_2 = pd.DataFrame(mbd, columns= ['poligono 2 x','poligono 2 y'])\n",
        "mbd_2.dropna(subset = [\"poligono 2 x\"], inplace=True)\n",
        "mbd_2p=Polygon(mbd_2.values.tolist())\n",
        "mbd_3 = pd.DataFrame(mbd, columns= ['poligono 3 x','poligono 3 y'])\n",
        "mbd_3p=Polygon(mbd_3.values.tolist())\n",
        "mbd_3.dropna(subset = [\"poligono 3 x\"], inplace=True)\n",
        "mbd_4 = pd.DataFrame(mbd, columns= ['poligono 4 x','poligono 4 y'])\n",
        "mbd_4.dropna(subset = [\"poligono 4 x\"], inplace=True)\n",
        "mbd_4p=Polygon(mbd_4.values.tolist())\n",
        "mbd_5 = pd.DataFrame(mbd, columns= ['poligono 5 x','poligono 5 y'])\n",
        "mbd_5.dropna(subset = [\"poligono 5 x\"], inplace=True)\n",
        "mbd_5p=Polygon(mbd_5.values.tolist())\n",
        "mbd_6 = pd.DataFrame(mbd, columns= ['poligono 6 x','poligono 6 y'])\n",
        "mbd_6.dropna(subset = [\"poligono 6 x\"], inplace=True)\n",
        "mbd_6p=Polygon(mbd_6.values.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JyUPVODooT-"
      },
      "source": [
        "lbd=pd.read_excel('Ksat.xlsx',sheet_name='low bulk density poli') #led bulk density\n",
        "lbd_1 = pd.DataFrame(lbd, columns= ['poligono 1 x','poligono 1 y'])\n",
        "lbd_1.dropna(subset = [\"poligono 1 x\"], inplace=True)\n",
        "lbd_1p=Polygon(lbd_1.values.tolist())\n",
        "lbd_2 = pd.DataFrame(lbd, columns= ['poligono 2 x','poligono 2 y'])\n",
        "lbd_2.dropna(subset = [\"poligono 2 x\"], inplace=True)\n",
        "lbd_2p=Polygon(lbd_2.values.tolist())\n",
        "lbd_3 = pd.DataFrame(lbd, columns= ['poligono 3 x','poligono 3 y'])\n",
        "lbd_3p=Polygon(lbd_3.values.tolist())\n",
        "lbd_3.dropna(subset = [\"poligono 3 x\"], inplace=True)\n",
        "lbd_4 = pd.DataFrame(lbd, columns= ['poligono 4 x','poligono 4 y'])\n",
        "lbd_4.dropna(subset = [\"poligono 4 x\"], inplace=True)\n",
        "lbd_4p=Polygon(lbd_4.values.tolist())\n",
        "lbd_5 = pd.DataFrame(lbd, columns= ['poligono 5 x','poligono 5 y'])\n",
        "lbd_5.dropna(subset = [\"poligono 5 x\"], inplace=True)\n",
        "lbd_5p=Polygon(lbd_5.values.tolist())\n",
        "lbd_6 = pd.DataFrame(lbd, columns= ['poligono 6 x','poligono 6 y'])\n",
        "lbd_6.dropna(subset = [\"poligono 6 x\"], inplace=True)\n",
        "lbd_6p=Polygon(lbd_6.values.tolist())\n",
        "lbd_7 = pd.DataFrame(lbd, columns= ['poligono 7 x','poligono 7 y'])\n",
        "lbd_7.dropna(subset = [\"poligono 7 x\"], inplace=True)\n",
        "lbd_7p=Polygon(lbd_7.values.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHe2YD3fwyNi"
      },
      "source": [
        "# import numpy because it will be needed in the definde fucntion\n",
        "import numpy as np\n",
        "# define a function for the bulk density class selection\n",
        "def bd_group_selector(x,y,z,lbd_6p,lbd_5p,lbd_4p,lbd_3p,lbd_2p,lbd_1p,lbd_7p,mbd_6p,mbd_5p,mbd_4p,mbd_3p,mbd_2p,mbd_1p,hbd_5p,hbd_4p,hbd_3p,hbd_2p,hbd_1p):\n",
        "  bd_group = np.zeros(np.shape(x))\n",
        "  for i in range(np.shape(x)[0]):\n",
        "    for j in range(np.shape(x)[1]):\n",
        "     point = Point(x[i,j],y[i,j])\n",
        "     if x[i,j] == 0 and y[i,j] == 0: #mare o  no data\n",
        "       bd_group[i,j] = -1\n",
        "     elif lbd_7p.contains(point) and z[i,j]<1.19:\n",
        "       bd_group[i,j] = 1\n",
        "     elif lbd_6p.contains(point) and z[i,j]<0.93:\n",
        "       bd_group[i,j] = 1\n",
        "     elif lbd_5p.contains(point) and z[i,j]<1.32:\n",
        "       bd_group[i,j] = 1\n",
        "     elif lbd_4p.contains(point) and z[i,j]<1.06:\n",
        "       bd_group[i,j] = 1\n",
        "     elif lbd_3p.contains(point) and z[i,j]<1.32:\n",
        "       bd_group[i,j] = 1\n",
        "     elif lbd_2p.contains(point) and z[i,j]<1.06:\n",
        "       bd_group[i,j] = 1\n",
        "     elif lbd_1p.contains(point) and z[i,j]<0.93:  \n",
        "       bd_group[i,j] = 1 \n",
        "     elif hbd_5p.contains(point) and 1.72<z[i,j]:\n",
        "       bd_group[i,j] = 3      \n",
        "     elif hbd_4p.contains(point) and 1.19<z[i,j]:\n",
        "       bd_group[i,j] = 3 \n",
        "     elif hbd_3p.contains(point) and 1.46<z[i,j]:\n",
        "       bd_group[i,j] = 3 \n",
        "     elif hbd_2p.contains(point) and 1.59<z[i,j]:\n",
        "       bd_group[i,j] = 3 \n",
        "     elif hbd_1p.contains(point) and 1.32<z[i,j]:\n",
        "       bd_group[i,j] = 3\n",
        "     elif mbd_6p.contains(point) and 1.59<=z[i,j]<=1.72:\n",
        "       bd_group[i,j] = 2\n",
        "     elif mbd_5p.contains(point) and 1.48<=z[i,j]<=1.72:\n",
        "       bd_group[i,j] = 2\n",
        "     elif mbd_4p.contains(point) and 0.93<=z[i,j]<=1.19:\n",
        "       bd_group[i,j] = 2\n",
        "     elif mbd_3p.contains(point) and 1.19<=z[i,j]<=1.46:\n",
        "       bd_group[i,j] = 2\n",
        "     elif mbd_2p.contains(point) and 1.30<=z[i,j]<=1.48:\n",
        "       bd_group[i,j] = 2\n",
        "     else:\n",
        "       bd_group[i,j] = 0\n",
        "  return bd_group\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFwQ9NcZhhrN"
      },
      "source": [
        "bd_group = bd_group_selector(x,y,z,lbd_6p,lbd_5p,lbd_4p,lbd_3p,lbd_2p,lbd_1p,lbd_7p,mbd_6p,mbd_5p,mbd_4p,mbd_3p,mbd_2p,mbd_1p,hbd_5p,hbd_4p,hbd_3p,hbd_2p,hbd_1p)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(bd_group)\n",
        "plt.colorbar()\n",
        "plt.title('bulck density group')\n",
        "plt.xlabel('Column #')\n",
        "plt.ylabel('Row #')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dwej3D6HAzk"
      },
      "source": [
        "# Ksat Goup table loading \n",
        "Ksat=pd.read_excel('Ksat.xlsx',sheet_name='GI High bulk') #med bulk density\n",
        "hb_l_ksat= pd.DataFrame(Ksat, columns= ['low x','low y'])\n",
        "hb_l_ksat.dropna(subset = [\"low x\"], inplace=True)\n",
        "hb_l_ksatp=Polygon(hb_l_ksat.values.tolist())\n",
        "hb_ml_ksat = pd.DataFrame(Ksat, columns= ['mod low x','mod low y'])\n",
        "hb_ml_ksat.dropna(subset = [\"mod low x\"], inplace=True)\n",
        "hb_ml_ksatp = Polygon(hb_ml_ksat.values.tolist())\n",
        "hb_mh_ksat = pd.DataFrame(Ksat, columns= ['mod high x','mod high y'])\n",
        "hb_mh_ksat.dropna(subset = ['mod high x'], inplace=True)\n",
        "hb_mh_ksatp=Polygon(hb_mh_ksat.values.tolist())\n",
        "\n",
        "Ksat=pd.read_excel('Ksat.xlsx',sheet_name='GI Med bulk') #med bulk density\n",
        "mb_l_ksat= pd.DataFrame(Ksat, columns= ['low x','low y'])\n",
        "mb_l_ksat.dropna(subset = [\"low x\"], inplace=True)\n",
        "mb_l_ksatp=Polygon(mb_l_ksat.values.tolist())\n",
        "mb_ml_ksat = pd.DataFrame(Ksat, columns= ['mod low x','mod low y'])\n",
        "mb_ml_ksat.dropna(subset = [\"mod low x\"], inplace=True)\n",
        "mb_ml_ksatp = Polygon(mb_ml_ksat.values.tolist())\n",
        "mb_mh_ksat = pd.DataFrame(Ksat, columns= ['mod high x','mod high y'])\n",
        "mb_mh_ksat.dropna(subset = ['mod high x'], inplace=True)\n",
        "mb_mh_ksatp=Polygon(mb_mh_ksat.values.tolist())\n",
        "mb_h_ksat = pd.DataFrame(Ksat, columns= ['high x','high y'])\n",
        "mb_h_ksat.dropna(subset = ['high x'], inplace=True)\n",
        "mb_h_ksatp=Polygon(mb_h_ksat.values.tolist())\n",
        "\n",
        "\n",
        "Ksat=pd.read_excel('Ksat.xlsx',sheet_name='GI Low bulk') #med bulk density\n",
        "lb_ml_ksat = pd.DataFrame(Ksat, columns= ['mod low x','mod low y'])\n",
        "lb_ml_ksat.dropna(subset = [\"mod low x\"], inplace=True)\n",
        "lb_ml_ksatp = Polygon(lb_ml_ksat.values.tolist())\n",
        "lb_mh_ksat = pd.DataFrame(Ksat, columns= ['mod high x','mod high y'])\n",
        "lb_mh_ksat.dropna(subset = ['mod high x'], inplace=True)\n",
        "lb_mh_ksatp=Polygon(lb_mh_ksat.values.tolist())\n",
        "lb_h_ksat = pd.DataFrame(Ksat, columns= ['high x','high y'])\n",
        "lb_h_ksat.dropna(subset = ['high x'], inplace=True)\n",
        "lb_h_ksatp=Polygon(lb_h_ksat.values.tolist())\n",
        "\n",
        "\n",
        "#Ksat Group assignement\n",
        "\n",
        "GKsat = np.zeros(np.shape(x))\n",
        "GKsatm = (1)\n",
        "for i in range(np.shape(x)[0]):\n",
        "    for j in range(np.shape(x)[1]):\n",
        "        point = Point(x[i,j],y[i,j])\n",
        "        if bd_group[i,j] == -1: #mare lago o no data\n",
        "            GKsat[i,j] = -1\n",
        "        elif bd_group [i,j] == 1:\n",
        "            if lb_ml_ksatp.contains(point):\n",
        "                GKsat[i,j] = 2\n",
        "            elif lb_mh_ksatp.contains(point):\n",
        "                GKsat[i,j] = 3\n",
        "            elif lb_h_ksatp.contains(point):\n",
        "                GKsat[i,j] = 4\n",
        "        elif bd_group [i,j] == 2:\n",
        "            if mb_l_ksatp.contains(point):\n",
        "                GKsat[i,j] = 1\n",
        "            elif mb_ml_ksatp.contains(point):\n",
        "                GKsat[i,j] = 2\n",
        "            elif mb_mh_ksatp.contains(point):\n",
        "                GKsat[i,j] = 3\n",
        "            elif mb_h_ksatp.contains(point):\n",
        "                GKsat[i,j] = 4\n",
        "        elif bd_group [i,j] == 3:\n",
        "            if hb_l_ksatp.contains(point):\n",
        "                GKsat[i,j] = 1\n",
        "            elif hb_ml_ksatp.contains(point):\n",
        "                GKsat[i,j] = 2\n",
        "            elif hb_mh_ksatp.contains(point):\n",
        "                GKsat[i,j] = 3\n",
        "        elif bd_group [i,j] == 0:\n",
        "            GKsat[i,j] = GKsatm\n",
        "        Gksatm = GKsat[i,j] # dato precedente: se il dato non Ã¨ presente viene assegnato il gruppo della cella accanto\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixAxsiwueHo_"
      },
      "source": [
        "# numer of cells with not enough data\n",
        "print(sum(sum(bd_group==0))/(np.shape(bd_group)[0]*np.shape(bd_group)[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkV4A8AGXU_O"
      },
      "source": [
        "# result plotting \n",
        "plt.imshow(GKsat, cmap='Set1',)\n",
        "plt.colorbar()\n",
        "plt.title('Ksat group')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnUysB9X0_JT"
      },
      "source": [
        "# save Ksat group\n",
        "Group_ksat = silt60100.meta\n",
        "Group_ksat.update(\n",
        "    dtype=rasterio.float32,\n",
        "    count = 1)\n",
        "\n",
        "# Create the file\n",
        "with rasterio.open('Group_ksat60-100.tif', 'w', **Group_ksat) as dst:\n",
        "        dst.write_band(1, GKsat.astype(rasterio.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eDIS7xokQjk"
      },
      "source": [
        "# 60-100 cm Ksat group estimation (Rosetta)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_3MXb55h4_l"
      },
      "source": [
        "sand_c60100 = sand60100.read(1).flatten()/1000\n",
        "silt_c60100 = silt60100.read(1).flatten()/1000\n",
        "clay_c60100 = clay60100.read(1).flatten()/1000\n",
        "bd_c60100 = bdod60100.read(1).flatten()/100\n",
        "split_sand_c60100 = np.split(sand_c60100,100)\n",
        "split_silt_c60100 = np.split(silt_c60100,100)\n",
        "split_clay_c60100 = np.split(clay_c60100,100)\n",
        "split_bd_c60100 = np.split(bd_c60100,100)\n",
        "\n",
        "dim=(np.shape(sand_c60100)[0])\n",
        "Ksat = np.zeros(dim)\n",
        "start = 0\n",
        "for i in range(100):\n",
        "  input_data = np.column_stack((split_sand_c60100[i],split_silt_c60100[i],split_clay_c60100[i],split_bd_c60100[i]))\n",
        "  np.savetxt('input_data.txt', input_data)\n",
        "  #create an empity output file\n",
        "  output_data  = np.array([0,0])\n",
        "  np.savetxt('output_data.txt', output_data)\n",
        "  %run /content/drive/MyDrive/Rosetta_3/Rpredict.py   -i   input_data.txt  -o  output_data.txt --predict  --sqlite=/content/drive/MyDrive/Rosetta_3/sqlite/Rosetta.sqlite\n",
        "  output = np.loadtxt('output_data.txt', delimiter=',')\n",
        "  finish = start+int(dim/100) \n",
        "  Ksat [start:finish] = output[:,4]\n",
        "  start = finish\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zytfy_V8h7gZ"
      },
      "source": [
        "np.savetxt('Ksat.txt', Ksat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7iq4mw9h9zq"
      },
      "source": [
        "Ksat_Rosetta = np.loadtxt('Ksat.txt', dtype= float)\n",
        "Ksat_R_img = np.reshape(Ksat_Rosetta,[1360,2240])\n",
        "Ksat_R_img = Ksat_R_img*(GKsat>0)+(GKsat<=0)*-75"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSnEKV-zh-t-"
      },
      "source": [
        "plt.imshow(Ksat_R_img, cmap='Set1',)\n",
        "plt.colorbar()\n",
        "plt.title('Ksat')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GzufSlHiAKC"
      },
      "source": [
        "# save Ksat group\n",
        "ksat_Rosetta = silt60100.meta\n",
        "ksat_Rosetta.update(\n",
        "    dtype=rasterio.float32,\n",
        "    count = 1)\n",
        "\n",
        "# Create the file\n",
        "with rasterio.open('ksat_Rosetta_60_100.tif', 'w', **ksat_Rosetta) as dst:\n",
        "        dst.write_band(1, Ksat_R_img.astype(rasterio.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7mv8sax4tMp"
      },
      "source": [
        "# 100 - 200 cm Ksat group estimation (Rawls and Brakensiek, 1983)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQXdiDTl6PP-"
      },
      "source": [
        "# load the clay content maps providing the server the map name, the reference system (only few RS are work properly), the pre-defined area object, the resolution and the data format.\n",
        "response = clay_wcs.getCoverage(\n",
        "    identifier='clay_100-200cm_mean', \n",
        "    crs='urn:ogc:def:crs:EPSG::54012',\n",
        "    bbox=bbox, \n",
        "    resx=250, resy=250, \n",
        "    format='GEOTIFF_INT16')\n",
        "# save the loaded file\n",
        "with open('.northIT_clay_100-200_mean.tif', 'wb') as file:\n",
        "    file.write(response.read())\n",
        "# import the saved file as a raster\n",
        "clay100200 = rasterio.open(\".northIT_clay_100-200_mean.tif\", driver=\"GTiff\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUFGAlDb6z3r"
      },
      "source": [
        "response = sand_wcs.getCoverage(\n",
        "    identifier='sand_100-200cm_mean', \n",
        "    crs='urn:ogc:def:crs:EPSG::54012',\n",
        "    bbox=bbox, \n",
        "    resx=250, resy=250, \n",
        "    format='GEOTIFF_INT16')\n",
        "# save the loaded file\n",
        "with open('.northIT_sand_100-200_mean.tif', 'wb') as file:\n",
        "    file.write(response.read())\n",
        "# import the saved file as a raster\n",
        "sand100200 = rasterio.open(\".northIT_sand_100-200_mean.tif\", driver=\"GTiff\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nfr0KLz7Igb"
      },
      "source": [
        "response = bdod_wcs.getCoverage(\n",
        "    identifier='bdod_100-200cm_mean', \n",
        "    crs='urn:ogc:def:crs:EPSG::54012',\n",
        "    bbox=bbox, \n",
        "    resx=250, resy=250, \n",
        "    format='GEOTIFF_INT16')\n",
        "# save the loaded file\n",
        "with open('.northIT_bdod_100-200_mean.tif', 'wb') as file:\n",
        "    file.write(response.read())\n",
        "# import the saved file as a raster\n",
        "bdod100200 = rasterio.open(\".northIT_bdod_100-200_mean.tif\", driver=\"GTiff\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeI5_ecQ7WCG"
      },
      "source": [
        "response = silt_wcs.getCoverage(\n",
        "    identifier='silt_60-100cm_mean', \n",
        "    crs='urn:ogc:def:crs:EPSG::54012',\n",
        "    bbox=bbox, \n",
        "    resx=250, resy=250, \n",
        "    format='GEOTIFF_INT16')\n",
        "with open('.northIT_silt_60-100_mean.tif', 'wb') as file:\n",
        "    file.write(response.read())\n",
        "silt100200 = rasterio.open(\".northIT_silt_60-100_mean.tif\", driver=\"GTiff\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D4RQC9S7it1"
      },
      "source": [
        "#transform the input data ind datagrame and det them in the tables unit of measure\n",
        "x = sand100200.read(1)/1000\n",
        "y = clay100200.read(1)/1000\n",
        "z = bdod100200.read(1)/100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_5BZkil8gbM"
      },
      "source": [
        "# import the pandas library for the dataframe managing\n",
        "import pandas as pd\n",
        "# import form the shaply library the fuction point and Polygon to trasform the \n",
        "# input raster gfeoreferenced data into a table point object and to transform \n",
        "# the loaded Table's polygon point in to a Polygon object\n",
        "from shapely.geometry import Point\n",
        "from shapely.geometry.polygon import Polygon\n",
        "\n",
        "#first chek of input data, if the poin are out of the polygon data raise an error\n",
        "#if ((sand100200.read(1)+silt100200.read(1))> 1000).any():\n",
        "#    raise Exception ('sand and clay % excede the 100%. check the input data!')\n",
        "\n",
        "# load data from the .xlsx file and transform them in Polygons \n",
        "hbd=pd.read_excel('Ksat.xlsx',sheet_name='high bulk density poli') #high bulk density\n",
        "hbd_1 = pd.DataFrame(hbd, columns= ['poligono 1 x','poligono 1 y'])\n",
        "hbd_1.dropna(subset = [\"poligono 1 x\"], inplace=True)\n",
        "hbd_1p=Polygon(hbd_1.values.tolist())\n",
        "hbd_2 = pd.DataFrame(hbd, columns= ['poligono 2 x','poligono 2 y'])\n",
        "hbd_2.dropna(subset = [\"poligono 2 x\"], inplace=True)\n",
        "hbd_2p=Polygon(hbd_2.values.tolist())\n",
        "hbd_3 = pd.DataFrame(hbd, columns= ['poligono 3 x','poligono 3 y'])\n",
        "hbd_3p=Polygon(hbd_3.values.tolist())\n",
        "hbd_3.dropna(subset = [\"poligono 3 x\"], inplace=True)\n",
        "hbd_4 = pd.DataFrame(hbd, columns= ['poligono 4 x','poligono 4 y'])\n",
        "hbd_4.dropna(subset = [\"poligono 4 x\"], inplace=True)\n",
        "hbd_4p=Polygon(hbd_4.values.tolist())\n",
        "hbd_5 = pd.DataFrame(hbd, columns= ['poligono 5 x','poligono 5 y'])\n",
        "hbd_5.dropna(subset = [\"poligono 5 x\"], inplace=True)\n",
        "hbd_5p=Polygon(hbd_5.values.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-czzCh1K8pii"
      },
      "source": [
        "mbd=pd.read_excel('Ksat.xlsx',sheet_name='med bulk density poli') #med bulk density\n",
        "mbd_1 = pd.DataFrame(mbd, columns= ['poligono 1 x','poligono 1 y'])\n",
        "mbd_1.dropna(subset = [\"poligono 1 x\"], inplace=True)\n",
        "mbd_1p=Polygon(mbd_1.values.tolist())\n",
        "mbd_2 = pd.DataFrame(mbd, columns= ['poligono 2 x','poligono 2 y'])\n",
        "mbd_2.dropna(subset = [\"poligono 2 x\"], inplace=True)\n",
        "mbd_2p=Polygon(mbd_2.values.tolist())\n",
        "mbd_3 = pd.DataFrame(mbd, columns= ['poligono 3 x','poligono 3 y'])\n",
        "mbd_3p=Polygon(mbd_3.values.tolist())\n",
        "mbd_3.dropna(subset = [\"poligono 3 x\"], inplace=True)\n",
        "mbd_4 = pd.DataFrame(mbd, columns= ['poligono 4 x','poligono 4 y'])\n",
        "mbd_4.dropna(subset = [\"poligono 4 x\"], inplace=True)\n",
        "mbd_4p=Polygon(mbd_4.values.tolist())\n",
        "mbd_5 = pd.DataFrame(mbd, columns= ['poligono 5 x','poligono 5 y'])\n",
        "mbd_5.dropna(subset = [\"poligono 5 x\"], inplace=True)\n",
        "mbd_5p=Polygon(mbd_5.values.tolist())\n",
        "mbd_6 = pd.DataFrame(mbd, columns= ['poligono 6 x','poligono 6 y'])\n",
        "mbd_6.dropna(subset = [\"poligono 6 x\"], inplace=True)\n",
        "mbd_6p=Polygon(mbd_6.values.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUgKffi68uI_"
      },
      "source": [
        "lbd=pd.read_excel('Ksat.xlsx',sheet_name='low bulk density poli') #led bulk density\n",
        "lbd_1 = pd.DataFrame(lbd, columns= ['poligono 1 x','poligono 1 y'])\n",
        "lbd_1.dropna(subset = [\"poligono 1 x\"], inplace=True)\n",
        "lbd_1p=Polygon(lbd_1.values.tolist())\n",
        "lbd_2 = pd.DataFrame(lbd, columns= ['poligono 2 x','poligono 2 y'])\n",
        "lbd_2.dropna(subset = [\"poligono 2 x\"], inplace=True)\n",
        "lbd_2p=Polygon(lbd_2.values.tolist())\n",
        "lbd_3 = pd.DataFrame(lbd, columns= ['poligono 3 x','poligono 3 y'])\n",
        "lbd_3p=Polygon(lbd_3.values.tolist())\n",
        "lbd_3.dropna(subset = [\"poligono 3 x\"], inplace=True)\n",
        "lbd_4 = pd.DataFrame(lbd, columns= ['poligono 4 x','poligono 4 y'])\n",
        "lbd_4.dropna(subset = [\"poligono 4 x\"], inplace=True)\n",
        "lbd_4p=Polygon(lbd_4.values.tolist())\n",
        "lbd_5 = pd.DataFrame(lbd, columns= ['poligono 5 x','poligono 5 y'])\n",
        "lbd_5.dropna(subset = [\"poligono 5 x\"], inplace=True)\n",
        "lbd_5p=Polygon(lbd_5.values.tolist())\n",
        "lbd_6 = pd.DataFrame(lbd, columns= ['poligono 6 x','poligono 6 y'])\n",
        "lbd_6.dropna(subset = [\"poligono 6 x\"], inplace=True)\n",
        "lbd_6p=Polygon(lbd_6.values.tolist())\n",
        "lbd_7 = pd.DataFrame(lbd, columns= ['poligono 7 x','poligono 7 y'])\n",
        "lbd_7.dropna(subset = [\"poligono 7 x\"], inplace=True)\n",
        "lbd_7p=Polygon(lbd_7.values.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwEt6gHc8zhs"
      },
      "source": [
        "# import numpy because it will be needed in the definde fucntion\n",
        "import numpy as np\n",
        "# define a function for the bulk density class selection\n",
        "def bd_group_selector(x,y,z,lbd_6p,lbd_5p,lbd_4p,lbd_3p,lbd_2p,lbd_1p,lbd_7p,mbd_6p,mbd_5p,mbd_4p,mbd_3p,mbd_2p,mbd_1p,hbd_5p,hbd_4p,hbd_3p,hbd_2p,hbd_1p):\n",
        "  bd_group = np.zeros(np.shape(x))\n",
        "  for i in range(np.shape(x)[0]):\n",
        "    for j in range(np.shape(x)[1]):\n",
        "     point = Point(x[i,j],y[i,j])\n",
        "     if x[i,j] == 0 and y[i,j] == 0: #mare o  no data\n",
        "       bd_group[i,j] = -1\n",
        "     elif lbd_7p.contains(point) and z[i,j]<1.19:\n",
        "       bd_group[i,j] = 1\n",
        "     elif lbd_6p.contains(point) and z[i,j]<0.93:\n",
        "       bd_group[i,j] = 1\n",
        "     elif lbd_5p.contains(point) and z[i,j]<1.32:\n",
        "       bd_group[i,j] = 1\n",
        "     elif lbd_4p.contains(point) and z[i,j]<1.06:\n",
        "       bd_group[i,j] = 1\n",
        "     elif lbd_3p.contains(point) and z[i,j]<1.32:\n",
        "       bd_group[i,j] = 1\n",
        "     elif lbd_2p.contains(point) and z[i,j]<1.06:\n",
        "       bd_group[i,j] = 1\n",
        "     elif lbd_1p.contains(point) and z[i,j]<0.93:  \n",
        "       bd_group[i,j] = 1 \n",
        "     elif hbd_5p.contains(point) and 1.72<z[i,j]:\n",
        "       bd_group[i,j] = 3      \n",
        "     elif hbd_4p.contains(point) and 1.19<z[i,j]:\n",
        "       bd_group[i,j] = 3 \n",
        "     elif hbd_3p.contains(point) and 1.46<z[i,j]:\n",
        "       bd_group[i,j] = 3 \n",
        "     elif hbd_2p.contains(point) and 1.59<z[i,j]:\n",
        "       bd_group[i,j] = 3 \n",
        "     elif hbd_1p.contains(point) and 1.32<z[i,j]:\n",
        "       bd_group[i,j] = 3\n",
        "     elif mbd_6p.contains(point) and 1.59<=z[i,j]<=1.72:\n",
        "       bd_group[i,j] = 2\n",
        "     elif mbd_5p.contains(point) and 1.48<=z[i,j]<=1.72:\n",
        "       bd_group[i,j] = 2\n",
        "     elif mbd_4p.contains(point) and 0.93<=z[i,j]<=1.19:\n",
        "       bd_group[i,j] = 2\n",
        "     elif mbd_3p.contains(point) and 1.19<=z[i,j]<=1.46:\n",
        "       bd_group[i,j] = 2\n",
        "     elif mbd_2p.contains(point) and 1.30<=z[i,j]<=1.48:\n",
        "       bd_group[i,j] = 2\n",
        "     else:\n",
        "       bd_group[i,j] = 0\n",
        "  return bd_group\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxjTaF0B83Ng"
      },
      "source": [
        "bd_group = bd_group_selector(x,y,z,lbd_6p,lbd_5p,lbd_4p,lbd_3p,lbd_2p,lbd_1p,lbd_7p,mbd_6p,mbd_5p,mbd_4p,mbd_3p,mbd_2p,mbd_1p,hbd_5p,hbd_4p,hbd_3p,hbd_2p,hbd_1p)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(bd_group)\n",
        "plt.colorbar()\n",
        "plt.title('bulck density group')\n",
        "plt.xlabel('Column #')\n",
        "plt.ylabel('Row #')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OixyjRnh87qe"
      },
      "source": [
        "# Ksat Goup table loading \n",
        "Ksat=pd.read_excel('Ksat.xlsx',sheet_name='GI High bulk') #med bulk density\n",
        "hb_l_ksat= pd.DataFrame(Ksat, columns= ['low x','low y'])\n",
        "hb_l_ksat.dropna(subset = [\"low x\"], inplace=True)\n",
        "hb_l_ksatp=Polygon(hb_l_ksat.values.tolist())\n",
        "hb_ml_ksat = pd.DataFrame(Ksat, columns= ['mod low x','mod low y'])\n",
        "hb_ml_ksat.dropna(subset = [\"mod low x\"], inplace=True)\n",
        "hb_ml_ksatp = Polygon(hb_ml_ksat.values.tolist())\n",
        "hb_mh_ksat = pd.DataFrame(Ksat, columns= ['mod high x','mod high y'])\n",
        "hb_mh_ksat.dropna(subset = ['mod high x'], inplace=True)\n",
        "hb_mh_ksatp=Polygon(hb_mh_ksat.values.tolist())\n",
        "\n",
        "Ksat=pd.read_excel('Ksat.xlsx',sheet_name='GI Med bulk') #med bulk density\n",
        "mb_l_ksat= pd.DataFrame(Ksat, columns= ['low x','low y'])\n",
        "mb_l_ksat.dropna(subset = [\"low x\"], inplace=True)\n",
        "mb_l_ksatp=Polygon(mb_l_ksat.values.tolist())\n",
        "mb_ml_ksat = pd.DataFrame(Ksat, columns= ['mod low x','mod low y'])\n",
        "mb_ml_ksat.dropna(subset = [\"mod low x\"], inplace=True)\n",
        "mb_ml_ksatp = Polygon(mb_ml_ksat.values.tolist())\n",
        "mb_mh_ksat = pd.DataFrame(Ksat, columns= ['mod high x','mod high y'])\n",
        "mb_mh_ksat.dropna(subset = ['mod high x'], inplace=True)\n",
        "mb_mh_ksatp=Polygon(mb_mh_ksat.values.tolist())\n",
        "mb_h_ksat = pd.DataFrame(Ksat, columns= ['high x','high y'])\n",
        "mb_h_ksat.dropna(subset = ['high x'], inplace=True)\n",
        "mb_h_ksatp=Polygon(mb_h_ksat.values.tolist())\n",
        "\n",
        "\n",
        "Ksat=pd.read_excel('Ksat.xlsx',sheet_name='GI Low bulk') #med bulk density\n",
        "lb_ml_ksat = pd.DataFrame(Ksat, columns= ['mod low x','mod low y'])\n",
        "lb_ml_ksat.dropna(subset = [\"mod low x\"], inplace=True)\n",
        "lb_ml_ksatp = Polygon(lb_ml_ksat.values.tolist())\n",
        "lb_mh_ksat = pd.DataFrame(Ksat, columns= ['mod high x','mod high y'])\n",
        "lb_mh_ksat.dropna(subset = ['mod high x'], inplace=True)\n",
        "lb_mh_ksatp=Polygon(lb_mh_ksat.values.tolist())\n",
        "lb_h_ksat = pd.DataFrame(Ksat, columns= ['high x','high y'])\n",
        "lb_h_ksat.dropna(subset = ['high x'], inplace=True)\n",
        "lb_h_ksatp=Polygon(lb_h_ksat.values.tolist())\n",
        "\n",
        "\n",
        "#Ksat Group assignement\n",
        "\n",
        "GKsat = np.zeros(np.shape(x))\n",
        "GKsatm = (1)\n",
        "for i in range(np.shape(x)[0]):\n",
        "    for j in range(np.shape(x)[1]):\n",
        "        point = Point(x[i,j],y[i,j])\n",
        "        if bd_group[i,j] == -1: #mare lago o no data\n",
        "            GKsat[i,j] = -1\n",
        "        elif bd_group [i,j] == 1:\n",
        "            if lb_ml_ksatp.contains(point):\n",
        "                GKsat[i,j] = 2\n",
        "            elif lb_mh_ksatp.contains(point):\n",
        "                GKsat[i,j] = 3\n",
        "            elif lb_h_ksatp.contains(point):\n",
        "                GKsat[i,j] = 4\n",
        "        elif bd_group [i,j] == 2:\n",
        "            if mb_l_ksatp.contains(point):\n",
        "                GKsat[i,j] = 1\n",
        "            elif mb_ml_ksatp.contains(point):\n",
        "                GKsat[i,j] = 2\n",
        "            elif mb_mh_ksatp.contains(point):\n",
        "                GKsat[i,j] = 3\n",
        "            elif mb_h_ksatp.contains(point):\n",
        "                GKsat[i,j] = 4\n",
        "        elif bd_group [i,j] == 3:\n",
        "            if hb_l_ksatp.contains(point):\n",
        "                GKsat[i,j] = 1\n",
        "            elif hb_ml_ksatp.contains(point):\n",
        "                GKsat[i,j] = 2\n",
        "            elif hb_mh_ksatp.contains(point):\n",
        "                GKsat[i,j] = 3\n",
        "        elif bd_group [i,j] == 0:\n",
        "            GKsat[i,j] = GKsatm\n",
        "        Gksatm = GKsat[i,j] # dato precedente: se il dato non Ã¨ presente viene assegnato il gruppo della cella accanto\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Yvin5XF9BTH"
      },
      "source": [
        "# result plotting \n",
        "plt.imshow(GKsat, cmap='Set1',)\n",
        "plt.colorbar()\n",
        "plt.title('Ksat group')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns0MgIsm9Grw"
      },
      "source": [
        "# save Ksat group\n",
        "Group_ksat = silt100200.meta\n",
        "Group_ksat.update(\n",
        "    dtype=rasterio.float32,\n",
        "    count = 1)\n",
        "\n",
        "# Create the file\n",
        "with rasterio.open('Group_ksat100-200.tif', 'w', **Group_ksat) as dst:\n",
        "        dst.write_band(1, GKsat.astype(rasterio.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoHNUINiktFY"
      },
      "source": [
        "# 100 - 200 cm Ksat group estimation (Rosetta)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wk97Lka6iTSO"
      },
      "source": [
        "sand_c100200 = sand100200.read(1).flatten()/1000\n",
        "silt_c100200 = silt100200.read(1).flatten()/1000\n",
        "clay_c100200 = clay100200.read(1).flatten()/1000\n",
        "bd_c100200 = bdod100200.read(1).flatten()/100\n",
        "split_sand_c100200 = np.split(sand_c100200,100)\n",
        "split_silt_c100200 = np.split(silt_c100200,100)\n",
        "split_clay_c100200 = np.split(clay_c100200,100)\n",
        "split_bd_c100200 = np.split(bd_c100200,100)\n",
        "\n",
        "dim=(np.shape(sand_c100200)[0])\n",
        "Ksat = np.zeros(dim)\n",
        "start = 0\n",
        "for i in range(100):\n",
        "  input_data = np.column_stack((split_sand_c100200[i],split_silt_c100200[i],split_clay_c[i],split_bd_c100200[i]))\n",
        "  np.savetxt('input_data.txt', input_data)\n",
        "  #create an empity output file\n",
        "  output_data  = np.array([0,0])\n",
        "  np.savetxt('output_data.txt', output_data)\n",
        "  %run /content/drive/MyDrive/Rosetta_3/Rpredict.py   -i   input_data.txt  -o  output_data.txt --predict  --sqlite=/content/drive/MyDrive/Rosetta_3/sqlite/Rosetta.sqlite\n",
        "  output = np.loadtxt('output_data.txt', delimiter=',')\n",
        "  finish = start+int(dim/100) \n",
        "  Ksat [start:finish] = output[:,4]\n",
        "  start = finish\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBNEL7xpiZWG"
      },
      "source": [
        "np.savetxt('Ksat.txt', Ksat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLkgy5muibyl"
      },
      "source": [
        "Ksat_Rosetta = np.loadtxt('Ksat.txt', dtype= float)\n",
        "Ksat_R_img = np.reshape(Ksat_Rosetta,[1360,2240])\n",
        "Ksat_R_img = Ksat_R_img*(GKsat>0)+(GKsat<=0)*-75"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxwvh8SYicqk"
      },
      "source": [
        "plt.imshow(Ksat_R_img, cmap='Set1',)\n",
        "plt.colorbar()\n",
        "plt.title('Ksat')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz9WT-2xieM6"
      },
      "source": [
        "# save Ksat group\n",
        "ksat_Rosetta = silt100200.meta\n",
        "ksat_Rosetta.update(\n",
        "    dtype=rasterio.float32,\n",
        "    count = 1)\n",
        "\n",
        "# Create the file\n",
        "with rasterio.open('ksat_Rosetta_100_200.tif', 'w', **ksat_Rosetta) as dst:\n",
        "        dst.write_band(1, Ksat_R_img.astype(rasterio.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmSuKUDPDbUd"
      },
      "source": [
        "#Min Ksat layer evaluation\n",
        "\n",
        "In the following section is realized a map with a value equal to 1 in all the pixel where the estimate Ksat value (or group for Rawls and Brakensiek, 1983) has the minimum value between 60 and 100 cm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r37ososSDae1"
      },
      "source": [
        "#import the velue evauated and saved form the above calculation\n",
        "Group_ksat100_200 = rasterio.open(\"Group_ksat100-200.tif\", driver=\"GTiff\")\n",
        "Group_ksat60_100 = rasterio.open(\"Group_ksat60-100.tif\", driver=\"GTiff\")\n",
        "Group_ksat0_60 = rasterio.open(\"Group_ksat0-60.tif\", driver=\"GTiff\")\n",
        "#estimate the position of min Ksat\n",
        "min_GI = (Group_ksat60_100.read(1)<Group_ksat0_60.read(1))*(Group_ksat60_100.read(1)<Group_ksat100_200.read(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2GgbjuBbZmf"
      },
      "source": [
        "# result plotting \n",
        "plt.imshow(min_GI, cmap='Set1',)\n",
        "plt.colorbar()\n",
        "plt.title('Area where the minimum Ksat is between 60 and 100 cm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_Y4fBYpbgm2"
      },
      "source": [
        "# save Ksat group\n",
        "min60_100 = silt060.meta\n",
        "min60_100.update(\n",
        "    dtype=rasterio.float32,\n",
        "    count = 1)\n",
        "\n",
        "# Create the file\n",
        "with rasterio.open('Min60_100_B.tif', 'w', **min60_100) as dst:\n",
        "        dst.write_band(1, min_GI.astype(rasterio.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmo6uBjoixQi"
      },
      "source": [
        "#open the velue evauated and saved form the above calculation\n",
        "Group_ksat100_200 = rasterio.open(\"ksat_Rosetta_100_200.tif\", driver=\"GTiff\")\n",
        "Group_ksat60_100 = rasterio.open(\"ksat_Rosetta_60_100.tif\", driver=\"GTiff\")\n",
        "Group_ksat0_60 = rasterio.open(\"ksat_Rosetta_0_60.tif\", driver=\"GTiff\")\n",
        "#estimate the position of min Ksat\n",
        "min_GI = (Group_ksat60_100.read(1)<Group_ksat0_60.read(1))*(Group_ksat60_100.read(1)<Group_ksat100_200.read(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBaigXSDE9r4"
      },
      "source": [
        "# result plotting \n",
        "plt.imshow(min_GI, cmap='Set1',)\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI2FbQzcE-EP"
      },
      "source": [
        "# result plotting \n",
        "plt.imshow(Group_ksat100_200.read(1), cmap='Set1',)\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skmL6mBkE-bA"
      },
      "source": [
        "# result plotting \n",
        "plt.imshow(Group_ksat60_100.read(1), cmap='Set1',)\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_Xz5oFbjHml"
      },
      "source": [
        "# result plotting \n",
        "plt.imshow(Group_ksat0_60.read(1), cmap='Set1',)\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzudooNIjRRQ"
      },
      "source": [
        "# save Ksat group\n",
        "min60_100 = silt060.meta\n",
        "min60_100.update(\n",
        "    dtype=rasterio.float32,\n",
        "    count = 1)\n",
        "\n",
        "# Create the file\n",
        "with rasterio.open('Min60_100_R.tif', 'w', **min60_100) as dst:\n",
        "        dst.write_band(1, min_GI.astype(rasterio.float32))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}